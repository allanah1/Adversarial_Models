# -*- coding: utf-8 -*-
"""Adversarial_Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SzURVUbCxwJ7AT6cUDM_2M6ZeMJdlhmM
"""

pip install neural_structured_learning

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import keras

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

from keras.models import Sequential
from keras.layers import Conv2D, Lambda, MaxPooling2D # convolution layers
from keras.layers import Dense, Dropout, Flatten # core layers

from keras.layers.normalization import BatchNormalization

from keras.preprocessing.image import ImageDataGenerator

from keras.utils.np_utils import to_categorical

import neural_structured_learning as nsl
import tensorflow_datasets as tfds

class HParams(object):
  def __init__(self):
    self.input_shape = [28, 28, 1]
    self.num_classes = 10
    self.conv_filters = [32, 64, 64]
    self.kernel_size = (3, 3)
    self.pool_size = (2, 2)
    self.num_fc_units = [64]
    self.batch_size = 32
    self.epochs = 5
    self.adv_multiplier = 0.2
    self.adv_step_size = 0.2
    self.adv_grad_norm = 'infinity'

HPARAMS = HParams()

datasets = tfds.load('mnist')

train_dataset = datasets['train']
test_dataset = datasets['test']

IMAGE_INPUT_NAME = 'image'
LABEL_INPUT_NAME = 'label'

def normalize(features):
  features[IMAGE_INPUT_NAME] = tf.cast(
      features[IMAGE_INPUT_NAME], dtype=tf.float32) / 255.0
  return features

def convert_to_tuples(features):
  return features[IMAGE_INPUT_NAME], features[LABEL_INPUT_NAME]

def convert_to_dictionaries(image, label):
  return {IMAGE_INPUT_NAME: image, LABEL_INPUT_NAME: label}

train_dataset = train_dataset.map(normalize).shuffle(10000).batch(HPARAMS.batch_size).map(convert_to_tuples)
test_dataset = test_dataset.map(normalize).batch(HPARAMS.batch_size).map(convert_to_tuples)

train_set_for_adv_model = train_dataset.map(convert_to_dictionaries)
test_set_for_adv_model = test_dataset.map(convert_to_dictionaries)

def build_base_model(hparams):
  """Builds a model according to the architecture defined in `hparams`."""
  inputs = tf.keras.Input(
      shape=hparams.input_shape, dtype=tf.float32, name=IMAGE_INPUT_NAME)

  x = inputs
  for i, num_filters in enumerate(hparams.conv_filters):
    x = tf.keras.layers.Conv2D(
        num_filters, hparams.kernel_size, activation='relu')(
            x)
    if i < len(hparams.conv_filters) - 1:
      # max pooling between convolutional layers
      x = tf.keras.layers.MaxPooling2D(hparams.pool_size)(x)
  x = tf.keras.layers.Flatten()(x)
  for num_units in hparams.num_fc_units:
    x = tf.keras.layers.Dense(num_units, activation='relu')(x)
  pred = tf.keras.layers.Dense(hparams.num_classes, activation='softmax')(x)
  model = tf.keras.Model(inputs=inputs, outputs=pred)
  return model

base_model = build_base_model(HPARAMS)

base_model.summary()

base_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
                   metrics=['acc'])
base_model.fit(train_dataset, epochs=HPARAMS.epochs)

results = base_model.evaluate(test_dataset)
named_results = dict(zip(base_model.metrics_names, results))
print('\naccuracy:', named_results['acc'])

#Train a model on fgsm attacked images with epsilon = 0.2
fgsm_config = nsl.configs.make_adv_reg_config(multiplier=0.2,adv_step_size=0.2,adv_grad_norm='infinity' )
fgsm_model = nsl.keras.AdversarialRegularization(build_base_model(HPARAMS), label_keys=[LABEL_INPUT_NAME], adv_config= fgsm_config)

fgsm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
                   metrics=['acc'])
fgsm_model.fit(train_set_for_adv_model, epochs = 5, batch_size= 64)

results = fgsm_model.evaluate(test_set_for_adv_model)
named_results = dict(zip(fgsm_model.metrics_names, results))
print('\naccuracy:', named_results['sparse_categorical_accuracy'])

#Train a model on PGD
pgd_config = nsl.configs.make_adv_reg_config(multiplier=0.2,adv_step_size=0.2,adv_grad_norm='infinity', pgd_epsilon= 0.2, pgd_iterations= 40)
pgd_model = nsl.keras.AdversarialRegularization(build_base_model(HPARAMS), label_keys=[LABEL_INPUT_NAME], adv_config= pgd_config)

pgd_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
                   metrics=['acc'])
pgd_model.fit(train_set_for_adv_model, epochs = 5, batch_size= 64)

results = pgd_model.evaluate(test_set_for_adv_model)
named_results = dict(zip(pgd_model.metrics_names, results))
print('\naccuracy:', named_results['sparse_categorical_accuracy'])

reference_fgsm_two = nsl.keras.AdversarialRegularization(
    base_model,
    label_keys=[LABEL_INPUT_NAME],
    adv_config=fgsm_config)
reference_fgsm_two.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc'])

reference_fgsm_one = nsl.keras.AdversarialRegularization(
    base_model,
    label_keys=[LABEL_INPUT_NAME],
    adv_config=nsl.configs.make_adv_reg_config(multiplier=0.2,adv_step_size=0.1,adv_grad_norm='infinity' ))
reference_fgsm_one.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc'])

reference_fgsm_three = nsl.keras.AdversarialRegularization(
    base_model,
    label_keys=[LABEL_INPUT_NAME],
    adv_config=nsl.configs.make_adv_reg_config(multiplier=0.2,adv_step_size=0.5,adv_grad_norm='infinity' ))
reference_fgsm_three.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc'])

models_to_eval = {
    'base': base_model,
    'fgsm-trained': fgsm_model.base_model,
    'pgd-trained': pgd_model.base_model
}
metrics = {
    name: tf.keras.metrics.SparseCategoricalAccuracy()
    for name in models_to_eval.keys()
}

def evaluate_attacks(perturb_model):
  perturbed_images, labels, predictions = [], [], []

  for batch in test_set_for_adv_model:
    perturbed_batch = perturb_model.perturb_on_batch(batch)
    # Clipping makes perturbed examples have the same range as regular ones.
    perturbed_batch[IMAGE_INPUT_NAME] = tf.clip_by_value(perturbed_batch[IMAGE_INPUT_NAME], 0.0, 1.0)
    y_true = perturbed_batch.pop(LABEL_INPUT_NAME)
    perturbed_images.append(perturbed_batch[IMAGE_INPUT_NAME].numpy())
    labels.append(y_true.numpy())
    predictions.append({})
    for name, model in models_to_eval.items():
      y_pred = model(perturbed_batch)
      metrics[name](y_true, y_pred)
      predictions[-1][name] = tf.argmax(y_pred, axis=-1).numpy()

  for name, metric in metrics.items():
    print('%s model accuracy: %f' % (name, metric.result().numpy()))
  
  return perturbed_images, labels, predictions

def plot_adv_img(perturbed_images, labels, predictions):
  batch_index = 0

  batch_image = perturbed_images[batch_index]
  batch_label = labels[batch_index]
  batch_pred = predictions[batch_index]

  batch_size = HPARAMS.batch_size
  n_col = 4
  n_row = (batch_size + n_col - 1) / n_col

  print('accuracy in batch %d:' % batch_index)
  for name, pred in batch_pred.items():
    print('%s model: %d / %d' % (name, np.sum(batch_label == pred), batch_size))

  plt.figure(figsize=(15, 15))
  for i, (image, y) in enumerate(zip(batch_image, batch_label)):
    y_base = batch_pred['base'][i]
    y_fgsm = batch_pred['fgsm-trained'][i]
    y_pgd = batch_pred['pgd-trained'][i]
    plt.subplot(n_row, n_col, i+1)
    plt.title('true: %d, base: %d, fgsm: %d, pgd: %d' % (y, y_base, y_fgsm, y_pgd))
    plt.imshow(tf.keras.preprocessing.image.array_to_img(image), cmap='gray')
    plt.axis('off')

  plt.show()

fgsm_one_img, fgsm_one_label, fgsm_one_predictions = evaluate_attacks(reference_fgsm_one)

plot_adv_img(fgsm_one_img, fgsm_one_label, fgsm_one_predictions)

fgsm_two_img, fgsm_two_label, fgsm_two_predictions = evaluate_attacks(reference_fgsm_two)

plot_adv_img(fgsm_two_img, fgsm_two_label, fgsm_two_predictions)

fgsm_three_img, fgsm_three_label, fgsm_three_predictions = evaluate_attacks(reference_fgsm_three)

plot_adv_img(fgsm_three_img, fgsm_three_label, fgsm_three_predictions)

"""## PGD Attacks"""

#PGD Attack with perturbations of budget 0.1
reference_pgd_one = nsl.keras.AdversarialRegularization(
    base_model,
    label_keys=[LABEL_INPUT_NAME],
    adv_config=nsl.configs.make_adv_reg_config(multiplier=0.2,adv_step_size=0.2,adv_grad_norm='infinity', pgd_epsilon= 0.1, pgd_iterations= 40))
reference_pgd_one.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc'])

#PGD Attack with perturbations of budget 0.2
reference_pgd_two = nsl.keras.AdversarialRegularization(
    base_model,
    label_keys=[LABEL_INPUT_NAME],
    adv_config=pgd_config)
reference_pgd_two.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc'])

#PGD Attack with perturbations of budget 0.5
reference_pgd_three = nsl.keras.AdversarialRegularization(
    base_model,
    label_keys=[LABEL_INPUT_NAME],
    adv_config=nsl.configs.make_adv_reg_config(multiplier=0.2,adv_step_size=0.2,adv_grad_norm='infinity', pgd_epsilon= 0.5, pgd_iterations= 40))
reference_pgd_three.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['acc'])

pgd_one_img, pgd_one_labels, pgd_one_predictions = evaluate_attacks(reference_pgd_one)

plot_adv_img(pgd_one_img, pgd_one_labels, pgd_one_predictions)

pgd_two_img, pgd_two_labels, pgd_two_predictions = evaluate_attacks(reference_pgd_two)

plot_adv_img(pgd_two_img, pgd_two_labels, pgd_two_predictions)

pgd_three_img, pgd_three_labels, pgd_three_predictions = evaluate_attacks(reference_pgd_three)

plot_adv_img(pgd_three_img, pgd_three_labels, pgd_three_predictions)

